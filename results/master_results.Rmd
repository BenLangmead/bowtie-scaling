Bowtie, Bowtie 2 and HISAT thread scaling results
========================================================

All of these results are based on the output of the [`master.py`](https://github.com/BenLangmead/bowtie-scaling/blob/master/thread_scaling/scripts/master.py) and [`master_tabulate.py`](https://github.com/BenLangmead/bowtie-scaling/blob/master/thread_scaling/scripts/master_tabulate.py) scripts in the [`bowtie-scaling`](https://github.com/BenLangmead/bowtie-scaling) repo.

```{r}
library(dplyr)
library(ggplot2)
```

```{r}
m <- read.table('showcase2016/results_showcase_2016.tsv', header=T, sep='\t')
head(m)
```

## Bowtie 

Configurations tested.  TODO: de-uglify this table.

```
bt-cleanparse-tt                bowtie	scaling	            WITH_THREAD_PROFILING=1 EXTRA_FLAGS="-DUSE_FINE_TIMER"	-I 250 -X 800
bt-cleanparse-tbbpin-spin	      bowtie	scaling	            WITH_THREAD_PROFILING=1 EXTRA_FLAGS="-DUSE_FINE_TIMER" WITH_TBB=1 WITH_AFFINITY=1	-I 250 -X 800
bt-cleanparse-tbbpin-heavy	    bowtie	scaling	            WITH_THREAD_PROFILING=1 EXTRA_FLAGS="-DUSE_FINE_TIMER" WITH_TBB=1 WITH_AFFINITY=1 NO_SPINLOCK=1	-I 250 -X 800
bt-cleanparse-tbbpin-q	        bowtie	scaling	            WITH_THREAD_PROFILING=1 EXTRA_FLAGS="-DUSE_FINE_TIMER" WITH_TBB=1 WITH_AFFINITY=1 NO_SPINLOCK=1 WITH_QUEUELOCK=1	-I 250 -X 800
#bt-cleanparse-tbbpin-co-q	    bowtie	scaling	            WITH_THREAD_PROFILING=1 EXTRA_FLAGS="-DUSE_FINE_TIMER" WITH_TBB=1 WITH_AFFINITY=1 WITH_QUEUELOCK=1 WITH_COHORTLOCK=1	-I 250 -X 800
bt-cleanparse-tbbpin-co-tktptl	bowtie	scaling	            WITH_THREAD_PROFILING=1 EXTRA_FLAGS="-DUSE_FINE_TIMER" WITH_TBB=1 WITH_AFFINITY=1 WITH_COHORTLOCK=1	-I 250 -X 800
bt-tt	                          bowtie	scaling-old-parsing	WITH_THREAD_PROFILING=1 EXTRA_FLAGS="-DUSE_FINE_TIMER"	-I 250 -X 800
bt-no-io	                      bowtie	no-io	              WITH_THREAD_PROFILING=1 EXTRA_FLAGS="-DUSE_FINE_TIMER" WITH_TBB=1 WITH_AFFINITY=1	-I 250 -X 800
bt-tbbpin-spin                	bowtie	scaling-old-parsing	WITH_THREAD_PROFILING=1 EXTRA_FLAGS="-DUSE_FINE_TIMER" WITH_TBB=1 WITH_AFFINITY=1	-I 250 -X 800
bt-tbbpin-heavy	                bowtie	scaling-old-parsing	WITH_THREAD_PROFILING=1 EXTRA_FLAGS="-DUSE_FINE_TIMER" WITH_TBB=1 WITH_AFFINITY=1 NO_SPINLOCK=1	-I 250 -X 800
bt-tbbpin-q	                    bowtie	scaling-old-parsing	WITH_THREAD_PROFILING=1 EXTRA_FLAGS="-DUSE_FINE_TIMER" WITH_TBB=1 WITH_AFFINITY=1 NO_SPINLOCK=1 WITH_QUEUELOCK=1	-I 250 -X 800
#bt-tbbpin-co-q	                bowtie	scaling-old-parsing	WITH_THREAD_PROFILING=1 EXTRA_FLAGS="-DUSE_FINE_TIMER" WITH_TBB=1 WITH_AFFINITY=1 WITH_QUEUELOCK=1 WITH_COHORTLOCK=1	-I 250 -X 800
bt-tbbpin-co-tktptl	            bowtie	scaling-old-parsing	WITH_THREAD_PROFILING=1 EXTRA_FLAGS="-DUSE_FINE_TIMER" WITH_TBB=1 WITH_AFFINITY=1 WITH_COHORTLOCK=1	-I 250 -X 800
```

### Bowtie unpaired

A challenge here is that original tinythreads is so bad, everyone else gets crowded with the scale_y_continuous below.  I'll plot

```{r}
mtmp <- m %>% filter(tool == 'bowtie' & paired == 'unp')
ggplot(mtmp, aes(x=threads, y=seconds, color=lock, linetype=version)) +
  geom_line() + geom_point() + theme_bw() +
  labs(y="Normalized running time", x="# threads") +
  coord_cartesian(ylim=c(0, 350))
```

A few remarkable things:
* Tinythreads with original parsing is terrible
* Looking at the 1-thread result (extreme left), there's a big difference between `bt-no-io` and everyone else.  Why would there be a difference *for a single thread*?  Examining in gdb, I noticed when the `tbb:task_group` is created, this creates *several* threads -- i.e. several messages like `New Thread 0x7fff69755700 (LWP 3164)` -- even with `-p 1`.  Why several?  Tinythreads only creates one with `-p 1`.
* Apart from tinythreads, improved parsing has very little effect.  When I use gdb to investigate where time is being spent for, e.g., `bt-cleanparse-tbbpin-q` 120-threads, it's clearly the case that most threads are waiting for the input lock.  So the big differences between the lock types suggests performance is dominated by lock overhead, not by the critical section per se.

### Bowtie paired-end

```{r}
mtmp <- m %>% filter(tool == 'bowtie' & paired == 'pe')
ggplot(mtmp, aes(x=threads, y=seconds, color=lock, linetype=version)) +
  geom_line() + geom_point() + theme_bw() +
  labs(y="Normalized running time", x="# threads") +
  coord_cartesian(ylim=c(0, max(mtmp$seconds)*1.05))
```

* Something fishy happened for 60-thread tinythreads original parsing -- super high
* Like with Bowtie unpaired results, not much evidence that cleaner parsing is making a difference.  Suggests that performance differences (biggest difference is spin vs everyone else) are due to lock overhead.

## HISAT 

Configurations tested:

```
hisat-tt                  hisat	master	        WITH_THREAD_PROFILING=1 EXTRA_FLAGS="-DUSE_FINE_TIMER"
hisat-tbbpin-q	          hisat	haswell	        WITH_THREAD_PROFILING=1 EXTRA_FLAGS="-DUSE_FINE_TIMER" WITH_TBB=1 WITH_AFFINITY=1 NO_SPINLOCK=1 WITH_QUEUELOCK=1
hisat-cleanparse-tbbpin-q	hisat	cleaner_parsing	WITH_THREAD_PROFILING=1 EXTRA_FLAGS="-DUSE_FINE_TIMER" WITH_TBB=1 WITH_AFFINITY=1 NO_SPINLOCK=1 WITH_QUEUELOCK=1
```

### HISAT unpaired

```{r}
mtmp <- m %>% filter(tool == 'hisat' & paired == 'unp')
ggplot(mtmp, aes(x=threads, y=seconds, color=lock, linetype=version)) +
  geom_line() + geom_point() + theme_bw() +
  labs(y="Normalized running time", x="# threads") +
  coord_cartesian(ylim=c(0, max(mtmp$seconds)*1.05))
```

* Both lock type and optimized parsing help very appreciably
* Haven't implemented no-io yet, so can't compare to "ideal"

### HISAT paired-end

```{r}
mtmp <- m %>% filter(tool == 'hisat' & paired == 'pe')
ggplot(mtmp, aes(x=threads, y=seconds, color=lock, linetype=version)) +
  geom_line() + geom_point() + theme_bw() +
  labs(y="Normalized running time", x="# threads") +
  coord_cartesian(ylim=c(0, max(mtmp$seconds)*1.05))
```

(same observations as for unpaired)

## Bowtie 2

Configurations tested:

```
bt2-master  bowtie2	master	WITH_THREAD_PROFILING=1 EXTRA_FLAGS="-DUSE_FINE_TIMER"	-I 250 -X 800
bt2-tbbpin-spin	bowtie2	master	WITH_THREAD_PROFILING=1 EXTRA_FLAGS="-DUSE_FINE_TIMER" WITH_TBB=1 WITH_AFFINITY=1	-I 250 -X 800
bt2-tbbpin-heavy	bowtie2	master	WITH_THREAD_PROFILING=1 EXTRA_FLAGS="-DUSE_FINE_TIMER" WITH_TBB=1 WITH_AFFINITY=1 NO_SPINLOCK=1	-I 250 -X 800
bt2-noio	bowtie2	no-io	WITH_THREAD_PROFILING=1 EXTRA_FLAGS="-DUSE_FINE_TIMER" WITH_TBB=1 WITH_AFFINITY=1	-I 250 -X 800
bt2-tbbpin-q	bowtie2	cohort_locking_ptl_tkt	WITH_THREAD_PROFILING=1 EXTRA_FLAGS="-DUSE_FINE_TIMER" WITH_TBB=1 WITH_AFFINITY=1 NO_SPINLOCK=1 WITH_QUEUELOCK=1	-I 250 -X 800
#bt2-tbbpin-co-q	bowtie2	cohort_locking_ptl_tkt	WITH_THREAD_PROFILING=1 EXTRA_FLAGS="-DUSE_FINE_TIMER" WITH_TBB=1 WITH_AFFINITY=1 WITH_QUEUELOCK=1 WITH_COHORTLOCK=1	-I 250 -X 800
bt2-tbbpin-co-tktptl	bowtie2	cohort_locking_ptl_tkt	WITH_THREAD_PROFILING=1 EXTRA_FLAGS="-DUSE_FINE_TIMER" WITH_TBB=1 WITH_AFFINITY=1 WITH_COHORTLOCK=1	-I 250 -X 800
bt2-cleanparse-tbbpin-spin	bowtie2	cleaner_parsing	WITH_THREAD_PROFILING=1 EXTRA_FLAGS="-DUSE_FINE_TIMER" WITH_TBB=1 WITH_AFFINITY=1	-I 250 -X 800
bt2-cleanparse-tbbpin-heavy	bowtie2	cleaner_parsing	WITH_THREAD_PROFILING=1 EXTRA_FLAGS="-DUSE_FINE_TIMER" WITH_TBB=1 WITH_AFFINITY=1 NO_SPINLOCK=1	-I 250 -X 800
bt2-cleanparse-tbbpin-q	bowtie2	cleaner_parsing	WITH_THREAD_PROFILING=1 EXTRA_FLAGS="-DUSE_FINE_TIMER" WITH_TBB=1 WITH_AFFINITY=1 NO_SPINLOCK=1 WITH_QUEUELOCK=1	-I 250 -X 800
#bt2-cleanparse-tbbpin-co-q	bowtie2	cleaner_parsing	WITH_THREAD_PROFILING=1 EXTRA_FLAGS="-DUSE_FINE_TIMER" WITH_TBB=1 WITH_AFFINITY=1 WITH_QUEUELOCK=1 WITH_COHORTLOCK=1	-I 250 -X 800
bt2-cleanparse-tbbpin-co-tktptl	bowtie2	cleaner_parsing	WITH_THREAD_PROFILING=1 EXTRA_FLAGS="-DUSE_FINE_TIMER" WITH_TBB=1 WITH_AFFINITY=1 WITH_COHORTLOCK=1	-I 250 -X 800
```

### Bowtie 2 unpaired

```{r}
mtmp <- m %>% filter(tool == 'bowtie2' & paired == 'unp')
ggplot(mtmp, aes(x=threads, y=seconds, color=lock, linetype=version)) +
  geom_line() + geom_point() + theme_bw() +
  labs(y="Normalized running time", x="# threads") +
  coord_cartesian(ylim=c(0, max(mtmp$seconds)*1.05))
```

* Optimized parsing has a huge positive benefit.
* Whether or not we use optimized parsing matters a lot.  If we use optimized parsing, the different lock types don't matter any more.
* Optimized parsing is *better* than no-io for many thread counts.  This is hard to explain, and is possibly indicative of a problem with no-io mode.  I forget now whether I had made the order randomization change before or after this experiment.  Either way, worth running the experiment again with current HEAD of bowtie2 no-io branch.

### Bowtie 2 paired-end

```{r}
mtmp <- m %>% filter(tool == 'bowtie2' & paired == 'pe')
ggplot(mtmp, aes(x=threads, y=seconds, color=lock, linetype=version)) +
  geom_line() + geom_point() + theme_bw() +
  labs(y="Normalized running time", x="# threads") +
  coord_cartesian(ylim=c(0, max(mtmp$seconds)*1.05))
```

* Very similar to Bowtie 2 unpaired but with less of a pronounced difference between optimized and original parsing

All results here are from `--sensitive` mode.  I've noticed appreciably different results in `--very-fast` mode.  I didn't run that mode for the showcase.

## Discussion

We have an idea we haven't tried yet for alleviating lock overhead.  We can make our `readLight`/`readPairLight` functions read multiple records at a time.  Within a thread, every (say) 10 calls to `readLight`/`readPairLight` actually causes synchronization & parsing to happen.  For the rest, we simply change a `ReadBuf*` to point to the next already-lightly-parsed read.  `finalize` remains the same.
